# MTH221 - Fundamentals of Machine Learning: Assignment 1

This repository contains the Jupyter notebook for the first assignment of the Fundamentals of Machine Learning course.
## Overview

This assignment is structured into two main parts:

- **Part I: Classification Problem**
- **Part II: Gradient Descent Implementation**

## Part I: Classification Problem

In this part, we explore various machine learning models to predict employee attrition based on the dataset provided by IBM on Kaggle.

### Steps Involved:

1. **Data Downloading**: Dataset can be accessed from [Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset).
2. **Exploratory Data Analysis (EDA)**: Employ statistical summaries and visualizations to uncover patterns and anomalies.
3. **Data Preprocessing**: Includes handling missing values, encoding categorical variables, feature scaling, etc.
4. **Model Implementation**: Employ models such as K-Nearest Neighbors, Naive Bayes, Perceptron, and Logistic Regression.
5. **Evaluation**: Assess model performance using metrics like accuracy, precision, recall, F1 score, and ROC-AUC curve.
6. **Discussion**: Analyze and reflect on the outcomes of the models.

## Part II: Gradient Descent Implementation

This part focuses on implementing the gradient descent algorithm to predict vehicle prices from the Vehicle Dataset available on Kaggle.

### Objectives:

1. **Dataset**: Download from [Kaggle](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho).
2. **Gradient Descent Algorithm**: Implement this algorithm without using any libraries except for Pandas and NumPy.
3. **Learning Rate Analysis**: Experiment with different learning rates to observe their impact on the number of iterations required for convergence.
4. **Visualization**: Display how the cost function changes with the number of iterations.
